{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np,pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.metrics import r2_score, precision_recall_fscore_support, \\\n",
    "    confusion_matrix, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = pd.read_csv(\"./data/raw.csv\")\n",
    "\n",
    "y = tests.iloc[:,8].values\n",
    "y = [0 if pd.isna(value) else value for value in y]\n",
    "X = tests.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(tests.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coeff >>>\",regressor.coef_)\n",
    "print(\"Intercept >>>\",regressor.intercept_)\n",
    "print(\"R-squared score >>>\", r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_pred)\n",
    "plt.xlabel(\"Prediction marked as Red\")\n",
    "plt.plot(y_test,c=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc = tests.iloc[:,:-2].values\n",
    "yc = tests.iloc[:,7].values\n",
    "\n",
    "Xc_train,Xc_test,yc_train,yc_test = train_test_split(Xc,yc,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(Xc_train,yc_train)\n",
    "\n",
    "yc_pred = classifier.predict(Xc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coeff >>>\",classifier.coef_)\n",
    "print(\"Intercept >>>\",classifier.intercept_)\n",
    "print(\"Prediction for [8,1,54,489,3,3652,5610] \",classifier.predict([[8,1,54,489,3,3652,5610]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cf-M >>>\\n\",confusion_matrix(yc_test,yc_pred))\n",
    "\n",
    "precison, recall, f1 ,s= precision_recall_fscore_support(yc_test,yc_pred,zero_division=0)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"F1 score >>>\",f1[1])\n",
    "print(\"Recall >>>\",recall[1])\n",
    "print(\"Precision >>>\",precison[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = classifier.predict_proba(Xc_test)\n",
    "print(\"AUC >>>\",roc_auc_score(yc_test,y_pred_proba[:,1]))\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(yc_test,classifier.predict_proba(Xc_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('sensitivity')\n",
    "plt.xlabel('1 - specificity')\n",
    "plt.plot(fpr,tpr)\n",
    "plt.plot([0,1],[0,1],linestyle = '--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class crex_utility:\n",
    "    def __init__(self):\n",
    "        self.ed = 0\n",
    "        self.nd = 0\n",
    "        self.l = 0\n",
    "        self.mat_S = 0\n",
    "        self.fuel = 0\n",
    "        self.ewt = 0\n",
    "        self.lwt = 0\n",
    "        self.fuel = 0\n",
    "        self.max_t = 0\n",
    "\n",
    "    def take_input(self):\n",
    "        try:\n",
    "            self.ed = float(input(\"Enter ed: \"))\n",
    "            self.nd = float(input(\"Enter nd: \"))\n",
    "            self.l = float(input(\"Enter l: \"))\n",
    "            self.mat_S = float(input(\"Enter mat_S: \"))\n",
    "            self.fuel = int(input(\"Enter fuel: \"))\n",
    "            self.ewt = float(input(\"Enter ewt: \"))\n",
    "            self.lwt = float(input(\"Enter lwt: \"))\n",
    "            \n",
    "            if any(value < 0 for value in [self.ed, self.nd, self.l, self.mat_S, self.fuel, self.ewt, self.lwt]):\n",
    "                raise ValueError(\"Negative values are not accepted!\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Invalid input: {e}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
